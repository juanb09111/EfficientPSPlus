VERSION: 2
MODEL:
  MASK_ON: True
  ANCHOR_GENERATOR:
    SIZES: [[32], [64], [128], [256]]  # One size for each in feature map
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]  # Three aspect ratios (same for all in feature maps)
  PROPOSAL_GENERATOR:
    NAME: "RPNCustom"
  RPN:
    HEAD_NAME: "DepthwiseSepRPNHead" # Normal RPN Head "StandardRPNHead"
    IN_FEATURES: ["P_4", "P_8", "P_16", "P_32"]
    # PRE_NMS_TOPK_TRAIN: 2000  # Per FPN level
    # PRE_NMS_TOPK_TEST: 2000  # Per FPN level
    # BBOX_REG_LOSS_TYPE: "smooth_l1"
    # BBOX_REG_LOSS_WEIGHT: 1.0
    # SMOOTH_L1_BETA: 0.11111111 # 1.0 / 9.0

    # # Detectron1 uses 2000 proposals per-batch,
    # # (See "modeling/rpn/rpn_outputs.py" for details of this legacy issue)
    # # which is approximately 1000 proposals per-image since the default batch size for FPN is 2.
    # POST_NMS_TOPK_TRAIN: 1000
    # POST_NMS_TOPK_TEST: 1000
    # SMOOTH_L1_BETA: 0.1111
    # IOU_THRESHOLDS: [0.3, 0.7]
  ROI_HEADS:
    NAME: "CustomROIHeads"
    # BATCH_SIZE_PER_IMAGE: 256 # number of proposals to sample for training
    # POSITIVE_FRACTION: 0.5 # fraction of positive (foreground) proposals to sample for training.
    IN_FEATURES: ["P_4", "P_8", "P_16", "P_32"]
    NUM_CLASSES: 3
    # PROPOSAL_APPEND_GT:
  #   IOU_THRESHOLDS: [0.5]
  #   # IOU_LABELS:
    SCORE_THRESH_TEST: 0.5 # First step of panoptic fusion module
    NMS_THRESH_TEST: 0.5 # Second step of panoptic fusion module
  # ROI_BOX_HEAD:
    # POOLER_RESOLUTION: 28
  #   POOLER_SAMPLING_RATIO: 2 # (maybe put to 2) The `sampling_ratio` parameter for the ROIAlign op.
  #   POOLER_TYPE: "ROIAlign" # "ROIAlignV2"
  #   SMOOTH_L1_BETA: 1.0
    # SCORE_THRESH_TEST: 0.7
  #   # NMS_THRESH_TEST: 0.5
  #   BBOX_REG_LOSS_TYPE: "smooth_l1"
  #   SMOOTH_L1_BETA: 1.0
  #   BBOX_REG_LOSS_WEIGHT: 1.0
  # ROI_MASK_HEAD:
  #   POOLER_RESOLUTION: 28
  #   POOLER_TYPE: "ROIAlignV2"
TEST:
  EVAL_PERIOD: 8000
#   DETECTIONS_PER_IMAGE: 30

INPUT:
  MIN_SIZE_TRAIN: (200,)
  MIN_SIZE_TEST: 200

BATCH_SIZE: 4
MODEL_CUSTOM:
  BACKBONE:
    EFFICIENTNET_ID: 5 # Id of the EfficienNet model
    LOAD_PRETRAIN: True # Load pretrained EfficienNet model

SOLVER:
  NAME: "Adam" # Adam or SGD

  WARMUP_ITERS: 4000 # Set to 0 for no warmup

  # Semantic and depth learning rates---------------
  BASE_LR_SEM_DEPTH: 0.0004570881896148751 #lr finder
  # BASE_LR_SEM_DEPTH: 0.0016 #from fuse net paper

  # Depth learning rate
  BASE_LR_DEPTH: 0.0006918309709189366 # lr finder
  
  # Instance learning rate
  BASE_LR_INSTANCE: 0.02

CHECKPOINT_PATH_TRAINING: ""
# CHECKPOINT_PATH_TRAINING: "tb_logs_2/maskrcnn_vkitti_cls3_4_gpus_warmup4k_best_Adam/version_0/checkpoints/last.ckpt"
# CHECKPOINT_PATH_INFERENCE: "'tb_logs_2/maskrcnn/version_38/checkpoints/epoch=126-step=2032.ckpt'"
CHECKPOINT_PATH_INFERENCE: "tb_logs_2/maskrcnn_vkitti_best_mask/version_1/checkpoints/epoch=204-step=5125.ckpt"
# DATASET_TYPE: "odFridgeObjects"
DATASET_TYPE: "vkitti2"

VKITTI_DATASET:
  STUFF_CLASSES: 12
  MAX_SAMPLES: 128 #Number of training samples, null for all
  SHUFFLE: True
  NORMALIZE:
    MEAN: (0.485, 0.456, 0.406)
    STD: (0.229, 0.224, 0.225)
  ORIGINAL_SIZE:
    HEIGHT: 375
    WIDTH: 1242
  RANDOMCROP:
    HEIGHT: 375
    WIDTH: 1242
  RESIZE:
    HEIGHT: 375
    WIDTH: 1242
  CENTER_CROP:
    # HEIGHT: 360
    # WIDTH: 1200
    HEIGHT: 200
    WIDTH: 1000
  HFLIP: 0.5
  DEPTH:
    K: 3
    SPARSITY_TRAINING: 0.05
    SPARSITY_EVAL: 0.20
    # MAX_DEPTH_POINTS: 20000 # Max val for HxW = 360x1200
    MAX_DEPTH_POINTS: 8000 # Max val for HxW = 200x1000
    MAX_DEPTH: 50
  DATASET_PATH:
    ROOT: "datasets/vkitti2"
    RGB: "vkitti_2.0.3_rgb"
    SEMANTIC: "vkitti_2.0.3_classSegmentation"
    INSTANCE: "vkitti_2.0.3_instanceSegmentation"
    DEPTH: "vkitti_2.0.3_depth"
    DEPTH_VIRTUAL_GT: "depth_virtual_gt"
    DEPTH_PROJ: "depth_proj"
    COCO_ANNOTATION: "kitti_coco.json"
    COCO_PANOPTIC_SEGMENTATION: "kitti_coco_panoptic"
    TWO_CH_PANOPTIC_SEGMENTATION: "kitti_2ch_panoptic"
    COCO_PANOPTIC_ANNOTATION: "kitti_coco_panoptic.json"
    TWO_CH_IMAGE_JSON: "kitti_2ch_panoptic.json"
    VALID_JSON: "kitti_coco_panoptic_valid.json"
    VALID_PRED_DIR: "preds_valid"
    PRED_DIR: "preds"
    PRED_DIR_SEMANTIC: "preds_semantic"
    PRED_DIR_INSTANCE: "preds_instance_best_mask"
    PRED_JSON: "vkitti2_panoptic_predictions.json"
    PRED_JSON_SEMANTIC: "vkitti2_semantic_predictions.json"
    PRED_JSON_INSTANCE: "vkitti2_instance_predictions.json"
  EXCLUDE: ["15-deg-left", "15-deg-right", "30-deg-left", "30-deg-right"]
  TRAINING_SCENES: ["Scene01", "Scene06", "Scene20"]
  EVAL_SCENES: ["Scene18"] # 339 unique samples
  TEST_SCENES: ["Scene02"] # 233 unique samples